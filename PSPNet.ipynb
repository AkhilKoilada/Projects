{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSF9oSM4-p6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torchvision import models,transforms,datasets\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import sklearn\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import torchvision.transforms.functional as TF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psUTGpDkgrrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def colormap(n):\n",
        "    cmap=np.zeros([n, 3]).astype(np.uint8)\n",
        "\n",
        "    for i in np.arange(n):\n",
        "        r, g, b = np.zeros(3)\n",
        "\n",
        "        for j in np.arange(8):\n",
        "            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))\n",
        "            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))\n",
        "            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2))\n",
        "\n",
        "        cmap[i,:] = np.array([r, g, b])\n",
        "\n",
        "    return cmap\n",
        "\n",
        "\n",
        "def Relabel(olabel,nlabel,tensor):\n",
        "  assert isinstance(tensor, torch.LongTensor), 'tensor needs to be LongTensor'\n",
        "  tensor[tensor == olabel] = nlabel\n",
        "  return tensor\n",
        "\n",
        "\n",
        "def ToLabel(image):\n",
        "  return torch.from_numpy(np.array(image)).long().unsqueeze(0)\n",
        "\n",
        "\n",
        "class Colorize:\n",
        "\n",
        "    def __init__(self, n=22):\n",
        "        self.cmap = colormap(256)\n",
        "        self.cmap[n] = self.cmap[-1]\n",
        "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
        "\n",
        "    def __call__(self, gray_image):\n",
        "        size = gray_image.size()\n",
        "        color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)\n",
        "\n",
        "        for label in range(1, len(self.cmap)):\n",
        "            mask = gray_image == label\n",
        "\n",
        "            color_image[0][mask] = self.cmap[label][0]\n",
        "            color_image[1][mask] = self.cmap[label][1]\n",
        "            color_image[2][mask] = self.cmap[label][2]\n",
        "\n",
        "        return color_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp6L5VUDZpow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataSet():\n",
        "\n",
        "  def __init__(self,image_path,mask_path):\n",
        "    self.image_paths = image_path\n",
        "    self.target_paths = mask_path\n",
        "    self.files = sorted(os.listdir(self.image_paths))\n",
        "    self.lables = sorted(os.listdir(self.target_paths))\n",
        "  def transform(self, image, mask):\n",
        "\n",
        "    resize = transforms.Resize(size=(224, 224))\n",
        "    image = resize(image)\n",
        "    mask = resize(mask)\n",
        "\n",
        "    normaliz=transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    # Transform to tensor\n",
        "    image = TF.to_tensor(image)\n",
        "\n",
        "    image=normaliz(image)\n",
        "\n",
        "    mask=ToLabel(mask)\n",
        "    mask=Relabel(255,21,mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    img_name = self.files[index]\n",
        "    label_name = self.lables[index]\n",
        "    image = Image.open(os.path.join(self.image_paths,img_name))\n",
        "    mask = Image.open(os.path.join(self.target_paths,label_name))\n",
        "    x, y = self.transform(image, mask)\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.files)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0egjMy9b_TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Data\n",
        "train_data=MyDataSet(\"/content/drive/My Drive/Herlev_Maps/Train/imgs\",\"/content/drive/My Drive/Herlev_Maps/Train/masks\")\n",
        "val_data=MyDataSet(\"/content/drive/My Drive/Herlev_Maps/Validation/imgs\",\"/content/drive/My Drive/Herlev_Maps/Validation/masks\")\n",
        "test_data=MyDataSet(\"/content/drive/My Drive/Herlev_Maps/Test/imgs\",\"/content/drive/My Drive/Herlev_Maps/Test/masks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxLX4z6TVsbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_load=torch.utils.data.DataLoader(train_data,batch_size=20,shuffle=True)\n",
        "val_load=torch.utils.data.DataLoader(val_data,batch_size=20,shuffle=True)\n",
        "test_load=torch.utils.data.DataLoader(test_data,batch_size=20,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLHjqnZECzfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CrossEntropyLoss2d(nn.Module):\n",
        "\n",
        "    def __init__(self, weight=None):\n",
        "        super(CrossEntropyLoss2d, self).__init__()\n",
        "\n",
        "        self.loss = nn.NLLLoss(weight)\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        return self.loss(F.log_softmax(outputs, dim = 1), targets[:,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_VE61FhqKFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='/content/drive/My Drive/DataSet/PSPnet:mark1.pth'):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "    if is_best:\n",
        "        print (\"=> Saving a new best\")\n",
        "        torch.save(state, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBCgfM3u7NDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(checkpoint_fpath,model):\n",
        "  checkpoint=torch.load(checkpoint_fpath)\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Tq2QkkA6nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy Metrics\n",
        "\n",
        "def pixel_accuracy(image1,image2):\n",
        "\timage1=np.array(image1)\n",
        "\timage2=np.array(image2)\n",
        "\t[row,col]=image1.shape\n",
        "\timage1=np.reshape(image1,(row*col,1))\n",
        "\timage2=np.reshape(image2,(row*col,1))\n",
        "\tcount=0\n",
        "\ttotal_count=0\n",
        "\tfor i in range(row*col):\n",
        "\t\t\ttotal_count+=1\n",
        "\t\t\tif(image1[i]==image2[i]):\n",
        "\t\t\t\tcount+=1\n",
        "\n",
        "\treturn count/(total_count + 1e-8)\n",
        "\n",
        "def mean_accuracy(image1,image2,num_classes):\n",
        "\timage1=np.array(image1)\n",
        "\timage2=np.array(image2)\n",
        "\t[row,col]=image1.shape\n",
        "\tcorrect_labels=np.zeros((num_classes,1))\n",
        "\tincorrect_labels=np.zeros((num_classes,1))\n",
        "\timage1=np.reshape(image1,(row*col,1))\n",
        "\timage2=np.reshape(image2,(row*col,1))\n",
        "\tfor i in range(row*col):\n",
        "\t\tif(image1[i]==image2[i]):\n",
        "\t\t\tcorrect_labels[image2[i]]+=1\n",
        "\t\telse:\n",
        "\t\t\tincorrect_labels[image2[i]]+=1\n",
        "\treturn ((sum(correct_labels/(correct_labels+incorrect_labels+1e-8)))[0]/sum((correct_labels+incorrect_labels)>0)[0]);\n",
        "\n",
        "\n",
        "def mean_IU(image1,image2,num_classes, ignore_index = None):\n",
        "\timage1=np.array(image1)\n",
        "\timage2=np.array(image2)\n",
        "\t[row,col]=image1.shape\n",
        "\tcorrect_predictions=np.zeros((num_classes,1))\n",
        "\tincorrect_predictions=np.zeros((num_classes,1))\n",
        "\tcorrect_labels=np.zeros((num_classes,1))\n",
        "\tincorrect_labels=np.zeros((num_classes,1))\n",
        "\timage1=np.reshape(image1,(row*col,1))\n",
        "\timage2=np.reshape(image2,(row*col,1))\n",
        "\n",
        "\tfor i in range(row*col):\n",
        "\t\tif(image1[i]==image2[i]):\n",
        "\t\t\tcorrect_predictions[image1[i]]+=1\n",
        "\t\t\tcorrect_labels[image1[i]]+=1\n",
        "\t\telse:\n",
        "\t\t\tincorrect_predictions[image1[i]]+=1\n",
        "\t\t\tincorrect_labels[image2[i]]+=1\n",
        "\tif(ignore_index):\n",
        "\t\tfor i in ignore_index:\n",
        "\t\t\tcorrect_predictions[i] = 0\n",
        "\t\t\tincorrect_predictions[i] = 0\n",
        "\t\t\tincorrect_labels[i] = 0\n",
        "\treturn ((sum(correct_predictions/(correct_predictions+incorrect_predictions+incorrect_labels+1e-8)))[0]\n",
        "\t\t\t/(num_classes - len(ignore_index)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9MUKBT-15P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(*models):\n",
        "\tfor model in models:\n",
        "\t\tfor module in model.modules():\n",
        "\t\t\tif isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "\t\t\t\tnn.init.kaiming_normal(module.weight)\n",
        "\t\t\t\tif module.bias is not None:\n",
        "\t\t\t\t\tmodule.bias.data.zero_()\n",
        "\t\t\telif isinstance(module, nn.BatchNorm2d):\n",
        "\t\t\t\tmodule.weight.data.fill_(1)\n",
        "\t\t\t\tmodule.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3-ybIFy-Gbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PyramidPool(nn.Module):\n",
        "\n",
        "\tdef __init__(self, in_features, out_features, pool_size):\n",
        "\t\tsuper(PyramidPool,self).__init__()\n",
        "\n",
        "\t\tself.features = nn.Sequential(\n",
        "\t\t\tnn.AdaptiveAvgPool2d(pool_size),\n",
        "\t\t\tnn.Conv2d(in_features, out_features, 1, bias=False),\n",
        "\t\t\tnn.BatchNorm2d(out_features, momentum=.95),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "\t\t)\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tsize=x.size()\n",
        "\t\t# output=F.upsample(self.features(x), size[2:], mode='bilinear')\n",
        "\t\toutput=F.interpolate(self.features(x), size[2:], mode='bilinear',align_corners=True)\n",
        "\t\treturn output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_uWjM1eCh9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PSP_Net\n",
        "class PSPNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, pretrained = True):\n",
        "        super(PSPNet,self).__init__()\n",
        "        print(\"initializing model\")\n",
        "        #init_net=deeplab_resnet.Res_Deeplab()\n",
        "        #state=torch.load(\"models/MS_DeepLab_resnet_trained_VOC.pth\")\n",
        "        #init_net.load_state_dict(state)\n",
        "        self.resnet = torchvision.models.resnet50(pretrained = True)\n",
        "\n",
        "\n",
        "        self.layer5a = PyramidPool(2048, 512, 1)\n",
        "        self.layer5b = PyramidPool(2048, 512, 2)\n",
        "        self.layer5c = PyramidPool(2048, 512, 3)\n",
        "        self.layer5d = PyramidPool(2048, 512, 6)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "        \tnn.Conv2d(4096,num_classes, 3, padding=1, bias=True),\n",
        "        )\n",
        "\n",
        "\n",
        "        initialize_weights(self.layer5a,self.layer5b,self.layer5c,self.layer5d,self.final)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        count=0\n",
        "\n",
        "        size=x.size()\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        # x = self.resnet.maxpool(x)\n",
        "        x = self.resnet.layer1(x)\n",
        "        x = self.resnet.layer2(x)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "        # x = self.resnet.avgpool(x)\n",
        "\n",
        "        x = self.final(torch.cat([\n",
        "        \tx,\n",
        "        \tself.layer5a(x),\n",
        "        \tself.layer5b(x),\n",
        "        \tself.layer5c(x),\n",
        "        \tself.layer5d(x),\n",
        "        ], 1))\n",
        "\n",
        "\n",
        "        # return F.upsample_bilinear(x,size[2:])\n",
        "        return F.interpolate(x,size[2:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMREWJrcUqeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device='cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ms1b7oCDAzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 5\n",
        "weights = torch.ones(num_classes)\n",
        "weights[0]=0\n",
        "weights=weights.to(device='cuda')\n",
        "\n",
        "\n",
        "model = PSPNet(num_classes=5, pretrained=True)\n",
        "model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxqJQ8egiA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4weight_decay=1e-4)\n",
        "criterion=CrossEntropyLoss2d(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvBZnfZOXjNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=20\n",
        "# model=load_checkpoint('/content/drive/My Drive/DataSet/PSPnet:mark1.pth',model)\n",
        "trainloss_data=[]\n",
        "accuracy_data=[]\n",
        "valloss_data=[]\n",
        "best_acc=0\n",
        "best_val_IU=0\n",
        "for epoch in range(epochs):\n",
        "  train_loss=0\n",
        "  val_loss=0\n",
        "  accuracy=0\n",
        "  model.train()\n",
        "  counter=0\n",
        "  print(\"Epoch : \",epoch+1)\n",
        "  for inputs,target in train_load: \n",
        "    counter+=1\n",
        "    inputs,target=inputs.to(device),target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(counter)\n",
        "    train_loss+=loss*inputs.size(0)\n",
        "  train_acc = [pixel_accuracy(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach()) for i in range(len(output))]\n",
        "  train_acc = sum(train_acc) / len(train_acc)\n",
        "  train_IU = [mean_IU(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach(), num_classes,  ignore_index = [num_classes - 1]) for i in range(len(output))]\n",
        "  train_IU = sum(train_IU) / len(train_IU)\n",
        "  train_loss=train_loss.cpu().data.detach().item()\n",
        "  print(\"Train Accuracy : \",train_acc)\n",
        "  print(\"Train Loss : \",train_loss/len(train_load.dataset))\n",
        "  print(\"Train IU : \",train_IU)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    counter=0\n",
        "    val_loss=0\n",
        "    for inputs,target in val_load:\n",
        "      counter+=1\n",
        "      print(counter)\n",
        "      inputs,target=inputs.to(device),target.to(device)\n",
        "      \n",
        "      output = model(inputs)\n",
        "      valloss = criterion(output, target)\n",
        "      val_loss+=valloss*inputs.size(0)\n",
        "\n",
        "    \n",
        "    val_acc = [pixel_accuracy(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach()) for i in range(len(output))]\n",
        "    val_acc = sum(val_acc) / len(val_acc)\n",
        "    val_IU = [mean_IU(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach(), num_classes, ignore_index = [num_classes - 1]) for i in range(len(output))]\n",
        "    val_IU = sum(val_IU) / len(val_IU)\n",
        "    val_loss=val_loss.cpu().data.detach().item()\n",
        "\n",
        "    is_best = bool(best_val_IU<val_IU)\n",
        "    \n",
        "    print(is_best)\n",
        "    if is_best==True:\n",
        "      best_val_IU=val_IU\n",
        "      save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "      }, is_best)\n",
        "  \n",
        "    print(\"Validation Accuracy : \",val_acc)\n",
        "    print(\"Validation Loss : \",val_loss/len(val_load.dataset))\n",
        "    print(\"Validation IU : \",val_IU)\n",
        "\n",
        "  print(\"\\n\")    \n",
        "  \n",
        "\n",
        "\n",
        "  # trainloss_data.append(float('{:.3f}'.format(train_loss)))\n",
        "  # valloss_data.append(float('{:.3f}'.format(val_loss)))\n",
        "  # accuracy_data.append(float('{:.4f}'.format(accuracy)))\n",
        "  # print(\"Accuracy : {:.6f}\".format(accuracy))\n",
        "  # print('Training Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzWhLiMkNzS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_checkpoint('/content/drive/My Drive/DataSet/PSPnet:mark1.pth',model)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  counter=0\n",
        "  test_loss=0\n",
        "  for inputs,target in test_load:\n",
        "    counter+=1\n",
        "    print(counter)\n",
        "    inputs,target=inputs.to(device),target.to(device)\n",
        "    \n",
        "    output = model(inputs)\n",
        "    testloss =  criterion(output, target)\n",
        "    test_loss+=testloss*inputs.size(0)\n",
        "\n",
        "test_acc = [pixel_accuracy(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach()) for i in range(len(output))]\n",
        "test_acc = sum(test_acc) / len(test_acc)\n",
        "test_IU = [mean_IU(output[i].cpu().data.max(0)[1].detach(),target[i,0,:,:].cpu().data.detach(), num_classes, ignore_index = [num_classes - 1]) for i in range(len(output))]\n",
        "test_IU = sum(test_IU) / len(test_IU)\n",
        "test_loss=test_loss.cpu().data.detach()\n",
        "print(\"Test Accuracy : \",test_acc)\n",
        "print(\"Test Loss : \",test_loss/len(test_load.dataset))\n",
        "print(\"Test IU : \",test_IU)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK27FA25-5wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir=\"/content/drive/My Drive/Herlev_Maps/Train/imgs\"\n",
        "ref_image=Image.open(\"/content/drive/My Drive/Herlev_Maps/Train/masks/148494967-148494986-001-d.bmp\")\n",
        "\n",
        "input_transform = transforms.Compose([\n",
        "\ttransforms.Resize(size=(224, 224)),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                      std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "im1 = input_transform(Image.open(\"/content/drive/My Drive/Herlev_Maps/Train/imgs/148494967-148494986-001.BMP\").convert('RGB')) #240,240\n",
        "input_transform1 = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "color_transform = Colorize()\n",
        "image_transform = transforms.ToPILImage()\n",
        "im2=input_transform1(Image.open(\"/content/drive/My Drive/Herlev_Maps/Train/imgs/148494967-148494986-001.BMP\"))\n",
        "im1=im1.to(device)\n",
        "label = model(Variable(im1, volatile=True).unsqueeze(0))#1,N,240,240\n",
        "label = color_transform(label[0].data.max(0)[1])#1,3,240,240\n",
        "output = image_transform(label)\n",
        "output = output.quantize(palette=ref_image)\n",
        "# output.save(label_name)\n",
        "output.show()\n",
        "im2=image_transform(im2)\n",
        "im2.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RM_pJDo9HxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}